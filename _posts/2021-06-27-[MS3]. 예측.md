---
layout: single
title:  "[MS3] Chapter3. 예측"
category: 'Mathematical Statistics'
toc: true
toc_sticky: true
---


서울대학교 통계학과 대학원 2021년도 1학년 1학기 통계이론1 수업의 정리내용입니다. <br/>
> **reference**: Lecture note (Prof.Jaeyong Lee),<br/> Mathematical Statistics : Basic Ideas and Selected Topics, Volume I, Second Edition By Peter J. Bickel, Kjell A. Doksum


# 3. 예측(prediction)

## 3.1 제곱오차하의 최적의 예측치

### 문제
* $Y \in \mathbb{R}^1$: 반응변수(response variable)
* $Z \in \mathbb{R}^d$: 예측변수(covariates)
   - $Y,Z$: 확률변수(or random vector)
* $MSEP = E(g(z)-Y)^2$을 최소화하는 함수 $g$를 찾으려 한다.
   - MSEP: mean squared prediction error

<br/>


### <참고>
1. 다른거리척도가 사용될 수 있다. (eg. $E \vert g(z) - Y \vert $)
2. 함수의 모임 $g$를 제한할 수 있다.

<center>

$g^* = argmin_{g\in \mathscr{G}}E(g(z)-Y)^2$ where $\mathscr{G}:$선형함수들의 모임

</center>


3. **추정**은 고정된 모수 $\theta$를 맞추는 문제,<br/> **예측**은 확률변수를 맞추는 문제.

<br/>

### $\textbf{Theorem[최적의 예측치]}$
Let $EY^2< \infty.  $
1. $EY = argmin_{c \in \mathbb{R}}E(Y-c)^2$
2. $Cov(Y-E[Y\vert Z], g(t))=0, ~\forall g(t) \in L^2$
3. $E[Y\vert Z] = argmin_{g(z) \in L^2}E(Y-g(z))^2$
<br/>

### 예(이변량정규분포)
### 예(다변량정규분포)

<br/><br/>

## 3.2 최적 선형 예측치(best linear prediction)
### $\textbf{Theorem[최적의 선형 예측치]}$
$EY^2, Var(Z), Var(Z)^{-1}$이 존재한다고 하자.
1. $z \in \mathbb{R}$ 일 때, $a_1 + b_1z = argmin_{a+bz, ~a,b\in\mathbb{R}} E(Y-(a+bz))^2$라 하면,<br/>

<center>

$a_1 = EY - b_1EZ, ~ b_1 = \dfrac{cov(Z,Y)}{Var(Z)}$

</center>

2. $z \in \mathbb{R}^d$일 때,


<center>

$\mu_L(Z) = argmin_{\mu(t)=a+b'z}E(Y-\mu(z))^2 = \mu_Y + (z-\mu_Z)^{\top}\beta$ <br/>
$\beta = \Sigma^{-1}_{ZZ} \sigma_{ZY}$

</center>



